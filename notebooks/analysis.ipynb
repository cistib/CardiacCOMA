{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set path to where `mlruns` directory is located (usually, the `CardiacCOMA` repository)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CARDIAC_COMA_REPO = \"/home/rodrigo/CISTIB/repos/CardiacCOMA/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import mlflow\n",
    "import os, sys\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import os; os.chdir(CARDIAC_COMA_REPO)\n",
    "from config.load_config import load_yaml_config, to_dict\n",
    "\n",
    "import ipywidgets as widgets\n",
    "from ipywidgets import interact\n",
    "from IPython.display import Image\n",
    "from mlflow.tracking import MlflowClient\n",
    "\n",
    "import pickle as pkl\n",
    "import pytorch_lightning as pl\n",
    "\n",
    "from argparse import Namespace\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#import surgeon_pytorch\n",
    "#from surgeon_pytorch import Inspect, get_layers\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from IPython import embed\n",
    "sys.path.insert(0, '..')\n",
    "\n",
    "import model.Model3D\n",
    "from utils.helpers import get_coma_args, get_lightning_module, get_datamodule\n",
    "from copy import deepcopy\n",
    "from pprint import pprint\n",
    "\n",
    "from copy import deepcopy\n",
    "from typing import List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlflow_helpers import \\\n",
    "    list_artifacts,\\\n",
    "    get_significant_loci,\\\n",
    "    get_metrics_cols, \\\n",
    "    get_params_cols, \\\n",
    "    get_runs_df, \\\n",
    "    get_good_runs,\\\n",
    "    summarize_loci_across_runs,\\\n",
    "    get_model_pretrained_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "TRACKING_URI = f\"file://{CARDIAC_COMA_REPO}/mlruns\"\n",
    "mlflow.set_tracking_uri(TRACKING_URI)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Select MLflow experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = MlflowClient()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "options = [exp.name for exp in mlflow.list_experiments()]\n",
    "\n",
    "experiment_w = widgets.Select(\n",
    "    options=options,\n",
    "    value=options[1]\n",
    ")\n",
    "display(experiment_w)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Retrieve run data from MLflow for the chosen experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_id = mlflow.get_experiment_by_name(experiment_w.value).experiment_id\n",
    "runs_df = get_runs_df(exp_name=experiment_w.value, only_finished=True)\n",
    "metrics = get_metrics_cols(runs_df)\n",
    "params = get_params_cols(runs_df)\n",
    "\n",
    "runs_df.loc[:, [*metrics, *params]].drop(\"params.platform\", axis=1).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RECON_LOSS_THRES = 1 # performance threshold for MSE mm2.\n",
    "run_ids = sorted([x[1] for x in runs_df[runs_df[\"metrics.test_recon_loss\"] < RECON_LOSS_THRES].index])\n",
    "run_ids_w = widgets.Select(description=\"Choose run:\", options={x[:10]: x for x in run_ids})\n",
    "display(run_ids_w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "run_id = run_ids_w.value\n",
    "run_info = runs_df.loc[exp_id, run_id].to_dict()\n",
    "artifact_uri = run_info[\"artifact_uri\"].replace(\"file://\", \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loci_summary_df = summarize_loci_across_runs(runs_df)\n",
    "loci_summary_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interact(\n",
    "    lambda run_id: get_significant_loci(runs_df, exp_id, run_id), \n",
    "    run_id=run_ids_w\n",
    "); "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def overwrite_ref_config(ref_config, run_info):\n",
    "    \n",
    "    '''\n",
    "    This is a workaround for adjusting the configuration of those runs that didn't have a YAML configuration file logged as an artifact.\n",
    "    '''\n",
    "    \n",
    "    config = deepcopy(ref_config)\n",
    "    config.network_architecture.latent_dim = int(run_info[\"params.latent_dim\"])\n",
    "    config.loss.regularization.weight = float(run_info[\"params.w_kl\"])\n",
    "    config.optimizer.parameters.lr = float(run_info[\"params.lr\"])\n",
    "    config.sample_sizes = [100, 100, 100, 100]\n",
    "    \n",
    "    return config\n",
    "\n",
    "\n",
    "ref_config = load_yaml_config(\"config_files/config.yaml\")\n",
    "config = overwrite_ref_config(ref_config, run_info)\n",
    "pprint(to_dict(config))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pl.utilities.seed.reset_seed() # seed_everything(seed=None)\n",
    "pl.utilities.seed.seed_everything(seed=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dm = get_datamodule(config, perform_setup=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = get_lightning_module(config, dm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = get_model_pretrained_weights(runs_df, exp_id, run_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "model.model.load_state_dict(_model_pretrained_weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assess perfomance of model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def mse(s1, s2=None):\n",
    "    if s2 is None:\n",
    "        s2 = torch.zeros_like(s1)\n",
    "    return ((s1-s2)**2).sum(-1).mean(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = dm.dataset[1]['s']\n",
    "s_hat = model(s)[0][0]\n",
    "mse(s, s_hat)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cardio",
   "language": "python",
   "name": "cardio"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
