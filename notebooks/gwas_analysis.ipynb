{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set path to where `mlruns` directory is located (usually, the `CardiacCOMA` repository)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "CARDIAC_COMA_REPO = \"/home/rodrigo/CISTIB/repos/CardiacCOMA/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import mlflow\n",
    "import os, sys\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import os; os.chdir(CARDIAC_COMA_REPO)\n",
    "from config.load_config import load_yaml_config, to_dict\n",
    "\n",
    "import ipywidgets as widgets\n",
    "from ipywidgets import interact\n",
    "from IPython.display import Image\n",
    "from mlflow.tracking import MlflowClient\n",
    "\n",
    "import pickle as pkl\n",
    "import pytorch_lightning as pl\n",
    "\n",
    "from argparse import Namespace\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#import surgeon_pytorch\n",
    "#from surgeon_pytorch import Inspect, get_layers\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from IPython import embed\n",
    "sys.path.insert(0, '..')\n",
    "\n",
    "import model.Model3D\n",
    "from utils.helpers import get_coma_args, get_lightning_module, get_datamodule\n",
    "from copy import deepcopy\n",
    "from pprint import pprint\n",
    "\n",
    "from copy import deepcopy\n",
    "from typing import List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlflow_helpers import \\\n",
    "    list_artifacts,\\\n",
    "    get_significant_loci,\\\n",
    "    get_metrics_cols, \\\n",
    "    get_params_cols, \\\n",
    "    get_runs_df, \\\n",
    "    get_good_runs,\\\n",
    "    summarize_loci_across_runs,\\\n",
    "    get_model_pretrained_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "TRACKING_URI = f\"file://{CARDIAC_COMA_REPO}/mlruns\"\n",
    "mlflow.set_tracking_uri(TRACKING_URI)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Select MLflow experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = MlflowClient()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8f3e808d9c1d4bb3827c265e9ab10785",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def experiment_selection_widget():\n",
    "    options = [exp.name for exp in mlflow.list_experiments()]\n",
    "\n",
    "    experiment_w = widgets.Select(\n",
    "      options=options,\n",
    "      value=options[1]\n",
    "    )\n",
    "    \n",
    "    return experiment_w\n",
    "\n",
    "exp_w = experiment_selection_widget()\n",
    "\n",
    "@interact\n",
    "def get_runs(exp_name=exp_w):  \n",
    "  try:\n",
    "    exp_id = mlflow.get_experiment_by_name(exp_name).experiment_id\n",
    "    runs_df = get_runs_df(exp_name=exp_name, only_finished=True)\n",
    "    metrics, params = get_metrics_cols(runs_df), get_params_cols(runs_df)  \n",
    "    # display(runs_df.loc[:, [*metrics, *params]].drop(\"params.platform\", axis=1).head(10))\n",
    "    return runs_df\n",
    "  except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "runs_df = get_runs_df(exp_name=exp_w.value, only_finished=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Retrieve run data from MLflow for the chosen experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "RECON_LOSS_THRES = 1. # performance threshold for MSE mm2.\n",
    "run_ids = sorted([x[1] for x in runs_df[runs_df[\"metrics.test_recon_loss\"] < RECON_LOSS_THRES].index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "18cf5b4774384a4c965622b646f725de",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "NameError",
     "evalue": "name 'exp_id' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [10]\u001b[0m, in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m display(run_ids_w)\n\u001b[1;32m      3\u001b[0m run_id \u001b[38;5;241m=\u001b[39m run_ids_w\u001b[38;5;241m.\u001b[39mvalue\n\u001b[0;32m----> 4\u001b[0m run_info \u001b[38;5;241m=\u001b[39m runs_df\u001b[38;5;241m.\u001b[39mloc[\u001b[43mexp_id\u001b[49m, run_id]\u001b[38;5;241m.\u001b[39mto_dict()\n\u001b[1;32m      5\u001b[0m artifact_uri \u001b[38;5;241m=\u001b[39m run_info[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124martifact_uri\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfile://\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'exp_id' is not defined"
     ]
    }
   ],
   "source": [
    "run_ids_w = widgets.Select(description=\"Choose run:\", options={x[:10]: x for x in run_ids})\n",
    "display(run_ids_w)\n",
    "run_id = run_ids_w.value\n",
    "run_info = runs_df.loc[exp_id, run_id].to_dict()\n",
    "artifact_uri = run_info[\"artifact_uri\"].replace(\"file://\", \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#runs_df_ = runs_df[runs_df[\"metrics.recon_loss\"].astype(float) < 0.4]\n",
    "ORDER_BY = {\"by\":\"count\", \"ascending\":False}\n",
    "ORDER_BY = {\"by\":\"min_P\", \"ascending\":True}\n",
    "ORDER_BY = {\"by\":\"-log10(min_P)\", \"ascending\":False}\n",
    "\n",
    "runs_df_ = runs_df[runs_df[\"params.w_kl\"].astype(float) == 0]\n",
    "loci_summary_df = summarize_loci_across_runs(runs_df)\n",
    "loci_summary_df[\"-log10(min_P)\"] = loci_summary_df.apply(lambda row: -np.log10(row[\"min_P\"]), axis=1)\n",
    "loci_summary_df.sort_values(**ORDER_BY, axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Statistics on the GWAS loci counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "signif_loci_dfs = {}\n",
    "dd = []\n",
    "\n",
    "def loci_count(run_df):\n",
    "    from collections import Counter\n",
    "    return dict(Counter([x[1] for x in run_df.index]))\n",
    "\n",
    "for run in runs_df.index:\n",
    "    \n",
    "    try:     \n",
    "      \n",
    "      pp = get_significant_loci(runs_df[runs_df[\"metrics.val_recon_loss\"] < 2], exp_id, run[1]) #.sort_values(by=[\"CHR\", \"BP\"], axis=0)\n",
    "      n_distinct_loci = len(loci_cnt.keys())\n",
    "      n_hits_with_duplication = sum(loci_cnt.values())\n",
    "      \n",
    "      ff = [  run[1], \n",
    "         runs_df.loc[run, \"metrics.test_recon_loss\"], \n",
    "         runs_df.loc[run, \"metrics.test_kld_loss\"], \n",
    "         runs_df.loc[run, \"params.latent_dim\"], \n",
    "         runs_df.loc[run, \"params.w_kl\"],\n",
    "         n_distinct_loci, \n",
    "         n_hits_with_duplication, \n",
    "         n_hits_with_duplication / n_distinct_loci             \n",
    "      ]\n",
    "      \n",
    "      signif_loci_dfs[run[1]] = pp\n",
    "      loci_cnt = loci_count(signif_loci_dfs[run[1]])\n",
    "      dd.append(ff)\n",
    "    except:\n",
    "      pass\n",
    "\n",
    "kk = pd.DataFrame(dd)\n",
    "\n",
    "kk.columns = [\n",
    "    \"run_id\",\n",
    "    \"test_mse\",\n",
    "    \"kld\",    \n",
    "    \"lat_dim\",\n",
    "    \"w_kl\",\n",
    "    \"n_loci\",\n",
    "    \"n_loci_dupl\",\n",
    "    \"ratio\"    \n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interact(\n",
    "    lambda xcol, ycol: sns.boxplot(x=xcol, y=ycol, data=kk),\n",
    "    xcol = widgets.Select(options=kk.columns),\n",
    "    ycol = widgets.Select(options=kk.columns)\n",
    ");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@interact\n",
    "def show_signif_loci(run_id=run_ids_w):\n",
    "    return get_significant_loci(runs_df, exp_id, run_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def overwrite_ref_config(ref_config, run_info):\n",
    "    \n",
    "    '''\n",
    "    This is a workaround for adjusting the configuration of those runs that didn't have a YAML configuration file logged as an artifact.\n",
    "    '''\n",
    "    \n",
    "    config = deepcopy(ref_config)\n",
    "    config.network_architecture.latent_dim = int(run_info[\"params.latent_dim\"])\n",
    "    config.loss.regularization.weight = float(run_info[\"params.w_kl\"])\n",
    "    config.optimizer.parameters.lr = float(run_info[\"params.lr\"])\n",
    "    config.sample_sizes = [100, 100, 100, 100]\n",
    "    \n",
    "    return config\n",
    "\n",
    "\n",
    "ref_config = load_yaml_config(\"config_files/config.yaml\")\n",
    "config = overwrite_ref_config(ref_config, run_info)\n",
    "pprint(to_dict(config))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pl.utilities.seed.reset_seed() # seed_everything(seed=None)\n",
    "pl.utilities.seed.seed_everything(seed=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dm = get_datamodule(config, perform_setup=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = get_lightning_module(config, dm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = get_model_pretrained_weights(runs_df, exp_id, run_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "model.model.load_state_dict(_model_pretrained_weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assess perfomance of model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mse(s1, s2=None):\n",
    "    if s2 is None:\n",
    "        s2 = torch.zeros_like(s1)\n",
    "    return ((s1-s2)**2).sum(-1).mean(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = dm.dataset[1]['s']\n",
    "s_hat = model(s)[0][0]\n",
    "mse(s, s_hat)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cardio",
   "language": "python",
   "name": "cardio"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
